{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_space_reductions.match_ups_over_polygons import get_zonal_match_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fake_data(N=200):\n",
    "\n",
    "    # creating example GeoDataframe for match-ups in EPSG 4326\n",
    "\n",
    "    xx = np.random.randint(low=-60, high=-33, size=N)*1.105\n",
    "\n",
    "    yy = np.random.randint(low=-4, high=20, size=N)*1.105\n",
    "\n",
    "    df = pd.DataFrame({'lon':xx, 'lat':yy})\n",
    "\n",
    "\n",
    "    df['geometry'] = df.apply(lambda x: Point(x['lon'], x['lat']), axis=1)\n",
    "\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry', crs={'init':'epsg:4326'})\n",
    "\n",
    "    gdf['Datetime'] = pd.date_range('2010-05-19', '2010-06-24',  periods=gdf.shape[0])\n",
    "\n",
    "    gdf.crs = {'init' :'epsg:4326'}\n",
    "\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netcdf_example():\n",
    "    import glob\n",
    "    cpath = r'C:\\Users\\Philipe Leal\\Dropbox\\Profissao\\Python\\OSGEO\\Matrizes\\NetCDF\\Time_Space_Concatenations\\time_space_reductions\\tests\\data'\n",
    "    path_file = glob.glob(cpath + '/*.nc' )\n",
    "\n",
    "\n",
    "    return  xr.open_mfdataset(path_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from time_space_reductions.netcdf_gdf_setter import Base_class_space_time_netcdf_gdf\n",
    "\n",
    "class Space_Time_Agg_over_polygons(Base_class_space_time_netcdf_gdf):\n",
    "    \n",
    "    def __init__(self, gdf, xarray_dataset=None, \n",
    "                 netcdf_temporal_coord_name='time',\n",
    "                 geo_series_temporal_attribute_name = 'Datetime',\n",
    "                 longitude_dimension='lon',\n",
    "                 latitude_dimension='lat',\n",
    "\t\t\t\t):\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Class description:\n",
    "        ------------------\n",
    "        \n",
    "            This class is a base class for ensuring that the given netcdf is in conformity with the algorithm.\n",
    "            \n",
    "            Ex: the Netcdf has to be sorted in ascending order for all dimensions (ex: time ,longitude, latitude). \n",
    "            Otherwise, the returned algorithm would return Nan values for all slices\n",
    "            \n",
    "            Also, it is mandatory for the user to define the longitude and latitude dimension Names (ex: 'lon', 'lat'),\n",
    "            since there is no stadardization for defining these properties in the Netcdf files worldwide.\n",
    "            \n",
    "            \n",
    "            \n",
    "        Attributes:\n",
    "            \n",
    "            gdf (geodataframe):\n",
    "            -----------------------\n",
    "                The geodataframe object containing geometries to be analyzed.\n",
    "            \n",
    "            xarray_dataset (None): \n",
    "            -----------------------\n",
    "            \n",
    "                the Xarry Netcdf object to be analyzed\n",
    "                \n",
    "                \n",
    "            netcdf_temporal_coord_name (str = 'time'): \n",
    "            -----------------------------------\n",
    "            \n",
    "                the name of the time dimension in the netcdf file\n",
    "                \n",
    "                \n",
    "            geo_series_temporal_attribute_name(str = 'Datetime'):\n",
    "            -----------------------------------\n",
    "            \n",
    "                the name of the time dimension in the geoseries file    \n",
    "                \n",
    "                \n",
    "            longitude_dimension (str = 'lon'): \n",
    "            ----------------------------------\n",
    "            \n",
    "                the name of the longitude/horizontal dimension in the netcdf file\n",
    "            \n",
    "            \n",
    "            latitude_dimension (str = 'lat'): \n",
    "            ----------------------------------\n",
    "                the name of the latitude/vertical dimension in the netcdf file\n",
    "        \n",
    "\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Base_class_space_time_netcdf_gdf.__init__(self, xarray_dataset=xarray_dataset, \n",
    "                 netcdf_temporal_coord_name=netcdf_temporal_coord_name,\n",
    "                 geo_series_temporal_attribute_name = geo_series_temporal_attribute_name,\n",
    "                 longitude_dimension=longitude_dimension,\n",
    "                 latitude_dimension=latitude_dimension,\n",
    "                )\n",
    "        \n",
    "        \n",
    "        self.__netcdf_ds = xarray_dataset\n",
    "        \n",
    "        self.__gdf = gdf\n",
    "        self.__geo_series_temporal_attribute_name = geo_series_temporal_attribute_name\n",
    "        \n",
    "        self.__netcdf_ds = self.netcdf_ds.sortby([self._temporal_coords, \n",
    "                                                  longitude_dimension,\n",
    "                                                  latitude_dimension])\n",
    "        \n",
    "        self.netcdf_ds = self._slice_bounding_box()\n",
    "    \n",
    "    \n",
    "    @ property\n",
    "    \n",
    "    def netcdf_ds(self):\n",
    "        \n",
    "        return self.__netcdf_ds\n",
    "    \n",
    "    @ netcdf_ds.setter\n",
    "    \n",
    "    def netcdf_ds(self, new_netcdf_ds):\n",
    "        '''\n",
    "        This property-setter alters the former netcdf_ds for the new gdf provided\n",
    "        \n",
    "        \n",
    "        '''\n",
    "     \n",
    "        self.__netcdf_ds = new_netcdf_ds\n",
    "    \n",
    "    \n",
    "    \n",
    "    @ property\n",
    "    \n",
    "    def gdf(self):\n",
    "        \n",
    "        return self.__gdf\n",
    "    \n",
    "    @ gdf.setter\n",
    "    \n",
    "    def gdf(self, new_gdf):\n",
    "        '''\n",
    "        This property-setter alters the former GDF for the new gdf provided\n",
    "        \n",
    "        \n",
    "        '''\n",
    "     \n",
    "        self.__gdf = new_gdf\n",
    "    \n",
    "    \n",
    "    def _slice_bounding_box(self):\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = self.gdf.geometry.total_bounds\n",
    "        \n",
    "        \n",
    "        dx = float(self.coord_resolution(self.spatial_coords['x']))\n",
    "        \n",
    "        dy = float(self.coord_resolution(self.spatial_coords['y']))\n",
    "        \n",
    "        xmin -= dx # to ensure full pixel slicing\n",
    "        \n",
    "        xmax += dx # to ensure full pixel slicing \n",
    "        \n",
    "        ymin -= dy # to ensure full pixel slicing \n",
    "        \n",
    "        ymax += dy # to ensure full pixel slicing \n",
    "        \n",
    "        \n",
    "        result = self.netcdf_ds.sel({self.spatial_coords['x']:slice(xmin, xmax),\n",
    "                                     self.spatial_coords['y']:slice(ymin, ymax)})\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def _slice_time_interval(self, time_init, final_time):\n",
    "        \n",
    "        \n",
    "        result = self.netcdf_ds.sel({self._temporal_coords:slice(time_init, final_time)})\n",
    "        \n",
    "\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _make_time_space_aggregations(self, \n",
    "                                      geoDataFrame, \n",
    "                                      date_offset,\n",
    "                                      netcdf_varnames, \n",
    "                                      agg_functions):\n",
    "        \n",
    "        Tmin = geoDataFrame[self.__geo_series_temporal_attribute_name].min()\n",
    "        \n",
    "        Tmax = geoDataFrame[self.__geo_series_temporal_attribute_name].max()\n",
    "        \n",
    "        time_init = Tmin - date_offset\n",
    "                \n",
    "        final_time = Tmax + date_offset\n",
    "        \n",
    "        netcdf_sliced = self._slice_time_interval(time_init, final_time)\n",
    "        \n",
    "        netcdf_sliced_as_gpd_geodataframe = self.netcdf_to_gdf(netcdf_sliced)\n",
    "            \n",
    "        if not  netcdf_sliced_as_gpd_geodataframe.empty:\n",
    "            \n",
    "            sjoined = gpd.sjoin(geoDataFrame, netcdf_sliced_as_gpd_geodataframe, how=\"left\", op='contains')\n",
    "            \n",
    "            sjoined_agg = sjoined[netcdf_varnames].agg(agg_functions)\n",
    "                \n",
    "               \n",
    "        else:\n",
    "            sjoined = geoDataFrame\n",
    "            \n",
    "            for key in netcdf_varnames:\n",
    "                sjoined[key] = np.nan\n",
    "                \n",
    "        \n",
    "        sjoined_agg = sjoined_agg.T\n",
    "        \n",
    "        sjoined_agg['period_sliced'] = time_init.strftime(\"%Y/%m/%d %H:%M:%S\") + ' <-> ' + final_time.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    \n",
    "        sjoined_agg.index.name = 'Variables'\n",
    "        \n",
    "        print(sjoined_agg)\n",
    "        \n",
    "        #sjoined_agg.index = geodataframe.index ?\n",
    "        \n",
    "        return sjoined_agg\n",
    "    \n",
    "    def _evaluate_space_time_agg(self, \n",
    "                                 netcdf_varnames=['adg_443_qaa'], \n",
    "                                 dict_of_windows=dict(time_window='1D'),\n",
    "                                 agg_functions=['nanmean','nansum','nanstd'],\n",
    "                                 verbose=True):\n",
    "        \n",
    "        \n",
    "        date_offset = pd.tseries.frequencies.to_offset(dict_of_windows['time_window'])\n",
    "        \n",
    "        \n",
    "        self.gdf2 = self.gdf.groupby(self.__geo_series_temporal_attribute_name).apply(lambda group:   \n",
    "            \n",
    "            self._make_time_space_aggregations(group,\n",
    "                                               date_offset=date_offset,\n",
    "                                               netcdf_varnames=netcdf_varnames,\n",
    "                                               agg_functions=agg_functions)\n",
    "            \n",
    "            )\n",
    "        \n",
    "        if self.gdf.index.name == None:\n",
    "\n",
    "            self.gdf.index.name = 'index'\n",
    "\n",
    "            idx_name = 'index'\n",
    "\n",
    "        else:\n",
    "            idx_name = self.gdf.index.name\n",
    "\n",
    "        T = self.gdf2\n",
    "        T[idx_name] =  list(self.gdf.index) * (len(self.gdf2) // len(self.gdf))\n",
    "        T = T.set_index('index', append=True, inplace=False).swaplevel(2, 0)\n",
    "\n",
    "        self.gdf2 = self.gdf.merge(T, on=idx_name)\n",
    "\n",
    "      \n",
    "    \n",
    "def _base(gdf,\n",
    "          netcdf,\n",
    "          netcdf_varnames =['adg_443_qaa'],\n",
    "          netcdf_temporal_coord_name='time',\n",
    "          geo_series_temporal_attribute_name = 'Datetime',\n",
    "          longitude_dimension='lon',\n",
    "          latitude_dimension='lat',\n",
    "          dict_of_windows=dict(time_window='M'),\n",
    "          agg_functions=['mean', 'max', 'min', 'std'],\n",
    "          verbose=True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Match_Upper = Space_Time_Agg_over_polygons(  gdf=gdf, \n",
    "                                                 xarray_dataset=netcdf, \n",
    "                                                 netcdf_temporal_coord_name=netcdf_temporal_coord_name,\n",
    "                                                 geo_series_temporal_attribute_name = geo_series_temporal_attribute_name,\n",
    "                                                 longitude_dimension=longitude_dimension,\n",
    "                                                 latitude_dimension=latitude_dimension)\n",
    "    \n",
    "   \n",
    "    Match_Upper._evaluate_space_time_agg(netcdf_varnames=netcdf_varnames, \n",
    "                                         dict_of_windows=dict_of_windows,\n",
    "                                         agg_functions=agg_functions,\n",
    "                                         verbose=verbose)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return Match_Upper.gdf2\n",
    "            \n",
    "            \n",
    "\n",
    "def get_zonal_match_up(netcdf, \n",
    "\t\t\t\t\t   gdf, \n",
    "                       netcdf_varnames =['adg_443_qaa'],\n",
    "                       dict_of_windows=dict(time_window='5D'),\n",
    "                       agg_functions=['mean', 'max', 'min', 'std'],\n",
    "                       netcdf_temporal_coord_name='time',\n",
    "                       geo_series_temporal_attribute_name = 'Datetime',\n",
    "                       longitude_dimension='lon',\n",
    "                       latitude_dimension='lat',\n",
    "                       verbose=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function does Match - Up operations from centroids of Geoseries or GeoDataFrames over Netcdfs.\n",
    "    \n",
    "\tAttributes:\n",
    "\t\n",
    "\t\tnetcdf (xarray Dataset/Dataarray):\n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tgdf (geopandas GeoDataFrame):\n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tnetcdf_varnames (list): a list containing the netcdf variable names to apply the aggregation.\n",
    "\n",
    "\t\t\tExample: netcdf_varnames=['adg_443_qaa']\n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tdict_of_windows(dictionary)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\tExample: dict_of_windows=dict(time_window='5D') # for 5 day window integration\n",
    "\t\t\t\n",
    "\t\t\t\tOther time integration options, follow pandas pattern (e.g.: 'Q', '3Y',...etc.)\n",
    "\t\t\t\t\t\t\t \n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tagg_functions(list):\n",
    "\t\t\n",
    "\t\t\tExample: agg_functions = ['mean', 'max', 'min', 'std']\n",
    "\t\t\t\n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tverbose (bool): it sets the function to verbose (or not). \n",
    "\t\t\n",
    "\t\t\tExample verbose=True\n",
    "\t\t--------------------------------------------------------------------------\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t\t(geopandas GeoDataFrame)\n",
    "\t\t\n",
    "\t\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(gdf.index, pd.MultiIndex):\n",
    "    \n",
    "        gdf = gdf.reset_index()\n",
    "    return _base(gdf=gdf.copy(), \n",
    "                netcdf=netcdf.copy(), \n",
    "                netcdf_varnames=netcdf_varnames,\n",
    "                dict_of_windows=dict_of_windows,\n",
    "                agg_functions=agg_functions,\n",
    "                verbose=verbose,\n",
    "                netcdf_temporal_coord_name=netcdf_temporal_coord_name,\n",
    "                geo_series_temporal_attribute_name = geo_series_temporal_attribute_name,\n",
    "                longitude_dimension=longitude_dimension,\n",
    "                latitude_dimension=latitude_dimension,\n",
    "                )\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\Python_3.8\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "<ipython-input-6-dece4842b27b>:3: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf.geometry = gdf.geometry.buffer(1.15) # in degrees\n"
     ]
    }
   ],
   "source": [
    "gdf = make_fake_data(3)\n",
    "\n",
    "gdf.geometry = gdf.geometry.buffer(1.15) # in degrees\n",
    "\n",
    "xnetcdf = get_netcdf_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mean  max  min  std                                period_sliced\n",
      "Variables                                                                    \n",
      "adg_443_qaa   NaN  NaN  NaN  NaN  2010/04/30 00:00:00 <-> 2010/05/31 00:00:00\n",
      "new_data      NaN  NaN  NaN  NaN  2010/04/30 00:00:00 <-> 2010/05/31 00:00:00\n",
      "             mean  max  min  std                                period_sliced\n",
      "Variables                                                                    \n",
      "adg_443_qaa   NaN  NaN  NaN  NaN  2010/05/31 00:00:00 <-> 2010/06/30 00:00:00\n",
      "new_data      NaN  NaN  NaN  NaN  2010/05/31 00:00:00 <-> 2010/06/30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "xnetcdf['new_data'] = xnetcdf['adg_443_qaa'] * 5 - 15\n",
    "\n",
    "Match_Upper = get_zonal_match_up(gdf=gdf, \n",
    "                          netcdf=xnetcdf,\n",
    "                            netcdf_varnames =['adg_443_qaa', 'new_data'],\n",
    "                            dict_of_windows=dict(time_window='1M'),\n",
    "                            agg_functions=['mean', 'max', 'min', 'std']\n",
    "\n",
    "                               )\n",
    "\n",
    "Match_Upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Upper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
